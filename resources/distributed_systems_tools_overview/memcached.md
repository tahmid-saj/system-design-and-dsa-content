# Memcached

## What is Memcached?

Memcached was introduced in 2003. It’s a key-value store distributed cache designed to store objects very fast. Memcached stores data in the form of a key-value pair. Both the key and the value are strings. This means that any data that has been stored will have to be serialized. So, Memcached doesn’t support and can’t manipulate different data structures.

Note: Serialization is the process of translating data into a format that can be transmitted or stored elsewhere. Later, reconstruction or deserialization of the data should be possible.

Memcached has a client and server component, each of which is necessary to run the system. The system is designed in a way that half the logic is encompassed in the server, whereas the other half is in the client. However, each server follows the shared-nothing architecture. In this architecture, servers are unaware of each other, and there’s no synchronization, data sharing, and communication between the servers.

Due to the disconnected design, Memcached is able to achieve almost a deterministic query speed (O(1)) serving millions of keys per second using a high-end system. Therefore, Memcached offers a high throughput and low latency.

<img width="559" alt="image" src="https://github.com/user-attachments/assets/6bf5bf5f-dccb-48f3-81c8-54c277b6b530">

As evident from the design of a typical Memcached cluster, Memcached scales well horizontally. The client process is usually maintained with the service host that also interacts with the authoritative storage (back-end database).

Memcached is a distributed in-memory cache system (not a database) written in C programming that is used to speed up dynamic web applications by reducing the amount of time required to retrieve data from databases. It stores data in memory, allowing for fast access, and can be used to cache the results of database queries, API calls, and other expensive operations.

Memcached is designed to be simple and efficient, with a small memory footprint and low overhead. It operates using a key-value store, where data is stored with a unique key that can be used to retrieve it later. It also supports distributed caching, allowing multiple cache servers to work together to store data.

### Facebook and Memcached

The data access pattern in Facebook requires frequent reads and updates because views are presented to the users on the fly instead of being generated ahead of time. Because Memcached is simple, it was an easy choice for the solution because Memcached started developing in 2003 whereas Facebook was developed in 2004. In fact, in some cases, Facebook and Memcached teams worked together to find solutions.

Note: Redis was developed in 2009. So, using Redis wasn’t a possibility at Facebook by then.

Some of the simple commands of Memcached include the following:

```bash
get <key_1> <key_2> <key_3> ...
set <key> <value> ...
delete <key>[<time>] ...
```

At Facebook, Memcached sits between the MySQL database and the web layer that uses roughly 28 TeraBytes of RAM spread across more than 800 servers (as of 2013). By an approximation of least recently used (LRU) eviction policy, Facebook is able to achieve a cache hit rate of 95%.

The following illustration shows the high-level design of caching architecture at Facebook. As we can see, out of a total of 50 million requests made by the web layer, only 2.5 million requests reach the persistence layer.

<img width="559" alt="image" src="https://github.com/user-attachments/assets/026ce7ae-7860-43a1-b471-b4bff0010306">

## How does Memcached work?

Conventional databases store data on a hard drive or preferably a solid-state drive (SSD). With Memcached, on the other hand, data is stored in memory so that it can be retrieved in microseconds, eliminating the delay caused by seek times when retrieving data. While it is possible to store data for a prolonged period, most data are automatically deleted after a certain amount of time. This is because Memcached is just a cache and not a database in the traditional sense. The least requested data is thus deleted as soon as there is no more space for new data. So, how exactly does the storage process work?

Memcached is also described as an in-memory key-value store. Using the TCP and IP protocols, a connection is first established with the server. If a user wants to retrieve specific data, Memcached will check whether it is available in the cache. If it is not, the required data will be retrieved from the main memory. The client then provides a key value for the data in question which is generated by the software library. Using a hashing algorithm, the client then determines which Memcached server the data, which is in the form of character strings, is to be stored on. Below are the five most important characteristics of Memcached:

- Data is only sent to one server.
- Data is stored as key-value pairs.
- The various servers do not share data with each other.
- The server only stores data in the memory.
- If there is not enough space, the server will delete the oldest data.

Consistent hashing is one of the techniques used by Memcached for distributing cached data across multiple servers in a cluster.

Memcached is a scalable, in-memory key-value store. As applications grow to accommodate more traffic (including data and requests), Memcached can be scaled by adding more servers (also called horizontal scaling) — something that is difficult to do with MySQL. The Memcached store can be distributed across multiple servers, all representing a single storage pool of cached data. Each server contains an associative array that represents a part of the pool. The Memcached client APIs use consistent hashing algorithms to determine which server to store and retrieve values for a particular key. The consistent hashing strategy allows for an even distribution of key-value pairs according to the memory allocated to each server in the pool, even when a server is added to or removed from the pool.

Each key-value pair is stored only in one location: there is no duplication across servers. Memcached servers in a Memcached memory pool are unaware of each other. The servers track which data in their local array was least-recently used, and will purge that data as needed to make room for newer requests (called an eviction).

Different keys are randomly mapped to servers in a pool, which can explain why, sometimes, one Memcached server can display different statistics from another. This does not necessarily mean that something is wrong; it simply means that the client is sending different keys to each server, which is how consistent hashing operates.

## Memcached architecture

The architecture of Memcached is designed to be simple, efficient, and scalable, making it well-suited for use in high-performance, distributed systems.

The general structure of Memcached’s architecture is relatively simple. It is similar to a distributed database system and consists of the application, a client library, and a pool of Memcached instances. Any number of these instances can be installed on a server’s main memory. We recommend activating one instance on each server that has memory to spare. These instances work together to acquire the free space that is available for the cache. The client library is the interface between the respective application and Memcached. It takes the data to be stored and places it on an existing server. Through its multi-thread architecture, Memcached can also use several process kernels simultaneously.

- Client Library — The client library is responsible for communicating with Memcached servers and sending requests for data storage and retrieval. The library provides a simple interface for storing and retrieving data and supports various programming languages.

- Memcached Server — The Memcached server is responsible for storing and retrieving data in memory. It listens for incoming requests from clients and performs the necessary operations to store and retrieve data.

- Storage Engine — Memcached stores data in memory as key-value pairs, and it uses a hash table to store the data. The storage engine is designed to be fast and efficient, and it uses a least recently used (LRU) eviction policy to manage the size of the cache.

- Network Communication — Memcached uses a simple ASCII-based protocol to communicate between clients and servers. The protocol is designed to be lightweight and efficient, and it supports a variety of operations, including storage, retrieval, deletion, and increment/decrement.

- Memory Allocator — Memcached uses a custom memory allocator to manage memory allocation and deallocation. The memory allocator is designed to be fast and efficient, and it minimizes memory fragmentation and maximizes memory utilization.

### Data model

Memcached uses a hash table to index data in the servers. When data is stored in Memcached, it is associated with a unique key that is used to look up the data later. The key is hashed to generate an index into the hash table, and the corresponding value is stored in the table at that index.

<img width="436" alt="image" src="https://github.com/user-attachments/assets/88ab801b-2142-46dd-a200-bd4016503131">

(Ref: Hash tables are a type of data structure used for implementing associative arrays, where keys map to values. They use a hash function to map each key to a unique index (hash value) in the table, where the corresponding value is stored. When a value is requested, the key is passed through the hash function to calculate the hash value, and the value is retrieved from the table at that index. Hash tables are commonly used for fast data lookups and can be found in various applications such as databases, web caches, and data structures for dictionaries, sets, and other collections of key-value pairs.)

When a client requests data, it provides the key and the Memcached server calculates the hash of the key to find the index in the hash table. If the data is found at that index, it is returned to the client. The server returns a “miss” to the client if the data is not found. The hash table is divided into several “buckets”, and each bucket is managed by a single server in a distributed Memcached setup. When a server receives a request for data, it checks its buckets to see if the data is present. If the data is not found, the request is forwarded to other servers in the cluster. This forwarding behavior is a classic of peer-to-peer (P2P) architecture. In this architecture, all nodes in the network can act as both clients and servers (there is no central point of control or coordination). While this architecture is simple, scalable, and fault-tolerant, it also presents some disadvantages such as increased network traffic. This is because nodes may need to communicate with multiple nodes to find the needed data.

<img width="403" alt="image" src="https://github.com/user-attachments/assets/20b6807d-b337-411a-aae2-fbcdd7503dbb">

Tree-based indexing algorithms, such as binary search trees or B-trees, provide logarithmic performance for data lookups. In other words, as the size of the input data increases, the time required to operate grows more slowly than linearly. However, tree-based indexing algorithms require more complex data structures and algorithms, which can impact the performance and scalability of the system. On the other hand, a hash table provides constant-time average performance for data lookups, which is important for the performance-critical use cases that Memcached is designed to handle. In this way, Memcached distributes data across multiple servers, providing high availability and scalability for large datasets.

- O: Order of Magnitude
- n: Input Size
- O(n): Time Complexity

<img width="388" alt="image" src="https://github.com/user-attachments/assets/c74a5134-30a0-4cc9-9603-c238d5aef39d">

## Memcached use cases

- Web application caching: Memcached is used to cache frequently accessed data in web applications, reducing the load on databases and improving the response time for users.

- Content Delivery Networks (CDN): Memcached is used to cache content such as images, videos, and web pages in CDN servers, reducing the latency and improving the delivery speed for users.

- Gaming: Memcached is used to store game state and player information, allowing for fast and reliable access to this data.

- E-commerce: Memcached is used to cache product information, customer data, and order information, reducing the load on databases and improving the responsiveness of the website.

- Social networking: Memcached is used to cache user profile information, friend lists, and other frequently accessed data, improving the performance of social networking applications.

Data that Memcached Usually Stores:

- Dynamic web content, such as HTML pages, images, and other multimedia files

- User session data, such as login information and shopping carts

- Database query results, such as lists of products or user information

- API responses, such as data from third-party services or internal microservices

- Application-generated data, such as results of computations or aggregations

## Memcached vs other data stores

### Memcached vs Redis

Both Redis and Memcached are open source, in-memory data stores, but they differ when it comes to their benefits and features. Memcached is often the preferred choice for simple applications requiring fewer memory resources, but it is limited when storing data in its serialized form. Redis' use of data structures provides much more power when working with large datasets and more ability to fine-tune cache contents and maintain greater efficiency in specific application scenarios.

Even though Memcached and Redis both belong to the NoSQL family, there are subtle aspects that set them apart:

Simplicity: Memcached is simple, but it leaves most of the effort for managing clusters left to the developers of the cluster. This, however, means finer control using Memcached. Redis, on the other hand, automates most of the scalability and data division tasks.

Persistence: Redis provides persistence by properties like append only file (AOF) and Redis database (RDB) snapshot. There’s no persistence support in Memcached. But this limitation can be catered to by using third-party tools.

Data types: Memcached stores objects in the form of key-value pairs that are both strings, whereas Redis supports strings, sorted sets, hash maps, bitmaps, and hyper logs. However, the maximum key or value size is configurable.

Memory usage: Both tools allow us to set a maximum memory size for caching. Memcached uses the slab allocation method for reducing fragmentation. However, when we update the existing entries’ size or store many small objects, there may be a wastage of memory. Nonetheless, there are configuration workarounds to resolve such issues.

Multithreading: Redis runs as a single process using one core, whereas Memcached can efficiently use multicore systems with multithreading technology. We could argue that Redis was designed to be a single-threaded process that reduces the complexity of multithreaded systems. Nonetheless, multiple Redis processes can be executed for concurrency. At the same time, Redis has improved over the years by tweaking its performance. Therefore, Redis can store small data items efficiently. Memcached can be the right choice for file sizes above 100 K.

Replication: As stated before, Redis automates the replication process via few commands, whereas replication in Memcached is again subject to the usage of third-party tools. Architecturally, Memcached can scale well horizontally due to its simplicity. Redis provides scalability through clustering that’s considerably complex.

<img width="625" alt="image" src="https://github.com/user-attachments/assets/c1820f7d-4526-420b-a346-03f738a5ac62">

To summarize, Memcached is preferred for smaller, simpler read-heavy systems, whereas Redis is useful for systems that are complex and are both read- and write-heavy.

### Can Memcached be used on disk?

Memcached cannot be directly used for disk-memory usage. However, Twitter released their Memcached on SSD, showing that is possible to use Memcached on disk. Instead of Memcached, other alternatives like Redis can be an option for in-memory and on-disk cache. Redis is a key-value database that is optimized for in-memory usage (sometimes called “in-memory DB”).

## Memcached advantages and disadvantages

Determining whether Memcached is the best caching solution for your needs depends on the requirements and the complexity of the application in question. Its temporary memory system can be useful, for example, when it comes to high-traffic web applications and websites accessing huge databases. Naturally, there are also a few disadvantages that come along with its many advantages. The following is a brief overview:

<img width="577" alt="image" src="https://github.com/user-attachments/assets/72193f7c-0e24-42fe-9541-801b8885d220">

## Memcached deployment and setup

1. Memcached can be installed on the local environment in Windows, Mac or Linux from online or via Docker
2. It can then be configured with the port and login credentials
3. We can also connect to the Memcached client using different frameworks in JS/TS, Python, Go, Java, PHP, etc
4. Additionally, Memcached is offered in cloud via AWS Elasticache and Memcached in the Azure marketplace

