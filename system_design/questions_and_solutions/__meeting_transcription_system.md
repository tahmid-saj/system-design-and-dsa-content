# Meeting transcription system

Design a meeting transcription system which uses a transcription engine to convert audio into text. Treat the transcription engine as a black box, and just assume that you have available this transcription engine.

## Requirements

### Questions

- To confirm, do we treat the transcription engine as a black box, and just assume that the ML code and logic are already provided to us, and that if we provide this model some audio (binary data), we'll get back the converted text of the audio?
  - Yes, that's correct

- Should the system incrementally provide the transcripted text as the audio is fed into the engine?
  - Yes, periodically provide the transcripted text every 2 seconds or so

- Should our system transcript a conversation with a single person, or a conversation in a meeting? Also, should we send the transcripted text to all the people in the meeting periodically?
  - Let's transcript a conversation with a single person, and in the DD talk about transcripting for all the people in the meeting, and sending them the periodic transcripted text.

- Do we need to store the transcripted text?
  - Yes, the transcription should be persisted

- How many DAU can we expect, and how many concurrent people will be using the system?
  - Assume 1M DAU, and around 50k concurrent people will be using the system

### Functional

- Users can send audio to the system, and get periodic transcripted text back
- Transcripted text should also be persisted
- Transcription can initially be done for a single-person conversation, then we'll design the system to handle multi-person conversations (while sending the transcripted text to all users in the meeting)

<br/>

- Assume 1M DAU, and around 50k concurrent people will be using the system (each sending a chunk of audio every 2-3 seconds)

### Non-functional

- Latency on periodic transcription updates:
  - Although latency is not a strict requirement, we still want to send back periodic transcription updates every 2-3 seconds
- Throughput:
  - It is not realistic for a single transcription engine instance / container to handle all the conversations for all concurrent users - we'll need to efficiently divide and conquer the throughput of the audio data among different transcription engine containers, where a single transcription engine container could serve a chunk of transcription requests from multiple users
- High volumes of storage is needed to persist audio and transcripted data

## Data model / entities

- Conversations:
  - This entity is used to group the transcripted messages within a conversation - it's used to help us better group and manage messages

    - conversationID
    - userID (host userID)
    - createdAt

- Messages:
  - This entity will store all the messages sent by users within a conversation. We'll store the transcription of the message here, and optionally store the binary audio data (will be relatively small and consist of a single sentence)

    - messageID
    - conversationID
    - userID
    - transcription, audio
    - sentAt

## API design

- Note that we’ll use userID if the user is authenticated to send requests to the endpoints. The userID could be placed in a session token or JWT in the Authentication header as such:
  - Authentication: Bearer

- The below caching header could also be applied to fetch frequently accessed data quicker. “no-cache” means that a browser may cache a response, but it must first send a validation request to an origin server before caching it. “Public” means that the entry can be cached by any intermediary such as a proxy server between the client and server - which is beneficial for static content like images and stylesheets. “Private” means that an entry can only be cached by the browser and no other intermediary. This is important for private content:
  - Cache-Control: no-cache max-age Private/Public

<br/>
<br/>

Websocket endpoints:

### Upgrade connection to websocket

- We'll assume that a conversationID has already been created for us in the database, and that we can connect to this "conversation" via websocket
- This endpoint will be used to establish the websocket connection. The Sec-WebSocket-Key header will be a value that the server will use to generate a response key to send websocket requests. The Sec-WebSocket-Version will be the websocket protocol version, usually 13.

Request:
```bash
GET /conversations/:conversationID
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: xyz
Sec-WebSocket-Version: 13
```

- In the response, the Sec-WebSocket-Accept header will usually be generated by combining the Sec-WebSocket-Key from the client with another hashed value. This resulting value will be returned to the client

Response:
```bash
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: xyz + hash value
```

### Send audio message

- The clients will send audio messages (binary format) via an established websocket connection

Request:
```bash
WS /conversations/:conversationID/messages
SEND {
  audio message in binary format
}
```

### Receive transcription response

- After a client sends their audio message, they'll get back the transcription response from the servers

Response:
```bash
RECV {
  messageID,
  transcription,
  sentAt
}
```

## HLD

### Client

- The client-side code will have the functionality to send a transcription request (to initiate the transcription of the audio data) to the Live response servers. Also, the client will have the code logic to start and stop the audio recording into binary data via the built-in JS MediaStream Recording API. The MediaStream Recording API provides primitive functions like start() and stop() to record audio. We can use this API or a similar one to retrieve the audio data (whenever a user might be "unmute") via the API's start() function, and stop() when the user goes "mute".

### Live response servers

- Clients will first establish a websocket connection with the Live person servers, and then send their audio data via the connection. The Live response servers will then batch the audio data from multiple clients, prior to sending the batched audio data to a L4 LB. The L4 LB will then send the batched request to a Transcription worker with the transcription engine. The Transcription worker will establish another websocket connection with the Live response servers, and provide the transcripted text back to the Live response servers for the batch.

- Polling vs websockets vs SSE could be another option, but in our system, for bidirectional communication purposes, websockets will work the most efficiently. If we used polling, it would lead to bandwidth issues on the server-side, where connections will need to be opened and closed frequently for the entire conversation. SSE is a unidirectional communication, thus it won't provide any bidirectional support.

<br/>

When a client sends an audio message, the process is:

1. Client establishes a websocket connection with the Live response servers

2. After the connection is set up, the client can then send an initial audio message input to the Live response servers - the Live response servers will then create a conversationID entry in the Conversations table, and also create an entry for this messageID in the Messages table

3. The Live response servers will compile a batch of audio message inputs (a fixed size batch). Then the Live response servers will send the batch request to a L4 LB.

4. The L4 LB will send route the batch request to a Transcription worker

5. The Transcription worker will then establish another websocket connection with the Live response servers. Note that this new websocket connection only exists because we need to connect our Live response servers to the Transcription workers containing the transcription logic. To reduce the network request time for this new websocket connections, we could also deploy the Live response servers close to the Transcription workers. Also, note that we could place the Transcription worker logic inside the Live response servers, however this tightly couples the number of Live response servers with the number of Transcription workers, thus, we'll keep them separate, and route the batched requests to the Transcription workers.

6. Once the new websocket connection between the Live response server and Transcription worker has been established, the Transcription worker will return the transcripted audio back to the Live response servers

7. The Live response servers will then store the transcripted audio in the database, and send it back to the clients

<br/>

When a client just reads the transcripted responses (without sending audio input), the process is:

1. If a client is just reading the transcripted responses without sending any audio input, the client will establish a websocket connection with the Live response servers
2. When the Live response server receives transcripted updates either from a connected Transcription worker or Redis PubSub (discussed in the DD), the Live response server will send back the received transcripted updates to the client

### Database

- The database will contain the conversations and messages data. The database will also store periodic transcription updates from the Live response servers in the Messages table
- Transcription data can become large very fast, since it doesn't take much effort to talk for long periods and generate large transcription outputs.
- If a single record in the Messages table takes up 100 bytes (for a sentence or two), then:
  - 100 bytes * 50k concurrent users or writes per second * 100k seconds in a day = 500 GB to the Messages table every day
- This means that we would need to use a DB like Cassandra which can tolerate the high volume of data and throughput. A single instance of DynamoDB or PostgreSQL (via AWS Aurora / RDS) can usually handle around 10 - 20k writes per second, thus we'll use Cassandra here.

Our CQL create-table statement will then look like the following, where the partition key is the conversationID, and the clustering keys are userID + sentAt:

```cql
create table messages (
  conversationID uuid,
  userID uuid,
  messageID uuid,
  transcription text,
  audio blob,
  sentAt timestamp,
  primary key (conversationID, (userID, sentAt))
with clustering order by (userID, sentAt asc))
```

- This way, we can query all the messages within the conversationID, and get back the result sorted by the userID + sentAt. We're using userID + sentAt as the clustering keys because we want the primary key of the rows within a single partition to be unique.

### Transcription workers

- These workers will connect to the Live response servers via websocket, and will also contain the transcription logic or model. Because the Live response servers will batch the requests, the Transcription workers can generate the transcripted text in parallel for different clients via multi-processing.

- We're using separate workers here because the transcription generation by far will take the longest time in the system, therefore we want it to be done separately for different clients, rather than blocking other requests from the client.

#### Scaling transcription workers

- Because the Transcription workers will frequently communicate with the Live response servers via websocket, and parform parallel operations, an IO optimized EC2 instance might be preferred here, where a single instance could contain multiple workers (containers with the transcription logic / model).

- Transcription workers can also be easily horizontally scaled by adding or removing containers, or vertically scalled by adding more CPU to the servers which are running the containers. We’ll also prefer a VM based instance like EC2 in which we can manage the infrastructure instead of a serverless service such as AWS Lambda which has a cold start latency. Based on the load, we could have roughly 50 - 100 workers, with a single EC2 instance containing multiple workers.

### L4 LB

- We’ll need an L4 load balancer to support traffic at the TCP level. L4 load balancers, let’s say using ELB in TCP mode can load balance websockets. When client’s need to connect to a Live response server, the L4 load balancer will route them to the Live response server they previously connected to or to a Live response server using the load balancing algorithm. However, if a Live response server goes down, the L4 load balancer can route the client to connect to another server instead.

- When a client needs to connect to the Live response server, the request will first go to the L4 load balancer, then to the server. There will actually be a symmetric websocket connection between both the client to the L4 load balancer, and between the L4 load balancer to the Live response server.

- L4 load balancers can be stateful and use sticky sessions to persist the server the client previously connected to. The sticky session can be implemented by identifying the user, usually with cookies or their IP address, and storing the user’s connected server for handling future requests.

- If clients disconnect from a Live response server, they can automatically reconnect to the same Live response server or another one via the L4 load balancer. Reconnecting to the same Live response server may be easier, as the session data in the L4 load balancer doesn’t have to be updated.

<img width="1000" alt="image" src="https://github.com/user-attachments/assets/5923896a-0ada-40be-af10-9d482d3b183f" />

## DD

### Handling multi-person conversations

To ensure our system can support multi-person conversations, where multiple people can join the same conversation and each generate / receive the transcripted audio, we'll need to add functionality to let the Live response servers send the transcripted audio (received from the Transcription workers) to other Live response servers.

#### Message delivery from one Live response server to another

Because we'll have users in the same conversation connected to different Live response servers, to deliver transcripted audio from one  server to another server, we can do the below and in ‘Message delivery between Live response / Chat servers’ (taken from the SDI 'Chat app'):

- Keep a Kafka topic per user:
  - This approach mainly won’t work because Kafka is not built for billions of topics (chat and meeting apps usually have billions of topics), and it will carry too much overhead for each topic, which may be 50 KB in size. This will result in terabytes of data to maintain for the Kafka topics.
  - Kafka is not optimal for short lived “micro topics” which are needed for a chat / meeting transcription app, where there can be numerous topics for conversations, users, etc, and subscribers can subscribe or unsubscribe at any point.
  - Redis PubSub is a lightweight solution which may be more appropriate for message delivery between Live response servers, since only currently subscribed subscribers will receive any messages sent to the topic.

- Consistent hashing of Chat / Live response servers:
  - By using a separate service discovery service using ZooKeeper to keep track of which clients should connect to which Chat / Live response servers, there will still be an overhead of maintaining those mappings during both disconnections and scaling events. Clients may frequently disconnect then reconnect to different servers, and all of this will need to be maintained and updated in service discovery, which will be complex to handle. Additionally, during scaling events in consistent hashing, Chat / Live response servers will handle a different set of clients in the hash ring - thus the mappings in ZooKeeper will need to be updated frequently during scaling of Chat / Live response servers.

- Offload to Redis PubSub:
  - Redis PubSub can maintain a lightweight hashmap of websocket connections. With Redis PubSub, a subscription can be created for a conversationID, and transcripted outputs can be published to that subscription which will be received at-most-once by the subscribers.
  - Live response server receiving transcripted output initiated by other Live response servers:
    - When recipient clients connect to the Live response server, the Live response server will subscribe to the conversationID’s topic via Redis PubSub. Any messages published to this conversationID’s topic will be forwarded to the recipient client by the recipient’s Live response server (since the Live response servers are currently subscribed).
  - Live response server sending transcripted output to other Live response servers:
    - The Live response server of the sender client will publish the message to the conversationID's topic. Any currently subscribed recipient Live response servers will receive that message published in that topic. The recipient Live response servers can then deliver the message to the appropriate recipient userIDs connected via websocket.

##### Redis PubSub

- Note that a single topic represents the conversationID

- Redis PubSub is lightweight and is an at-most-once delivery, which means that it doesn’t guarantee message delivery. If there’s no subscribers listening, then the message will be lost, and stored in the Messages table.

- Redis PubSub is appropriate for this design because it sends messages only when there are currently subscribed Live response servers, and if there are no subscribed Live response servers (likely the case for a single-person conversation), then the message is not received. This is a mock of how a chat app operates as well.

- One issue with this approach is that there is an all-to-all relationship between Live response servers and Redis cluster servers, where we’ll need connections for all those relationships. However, Redis PubSub is much more lightweight than Kafka, and will not take up as much bandwidth.

##### Redis cluster

- Topics will also be distributed across nodes within a Redis cluster.

- Also, the Redis clusters could be replicated - when one cluster is down, another replica can still receive from / send to subscribed Live response servers. There may be overhead in replication of Redis clusters, however Redis PubSub is more lightweight than most queue solutions (due to it’s at-most-once delivery) such as Kafka and SQS, thus it will be less complex in replicating it since there’s less persisted data to replicate.

#### Only users talking will send requests to Transcription workers

- Note that in a multi-person conversation, only users currently talking will send requests to the Transcription workers to generate the transcripted outputs. If a user is "mute" during a conversation, then they'll still establish a websocket connection with the Live response servers, and then the Live response servers will receive the transcription outputs from either Redis PubSub or the Transcription workers. The Live response servers will then send these transcription outputs back to the "mute" user.

### Using L4 LB's sticky sessions to persist websocket connection mappings

- Because we are not tightly coupling the Live response servers together with the Transcription workers, we'll batch the audio data from multiple conversations. This means that the same conversationID's transcription requests might be routed to the same Transcription worker for the duration of the conversation via the L4 LB between the Live response servers and the Transcription workers.

- The same conversationID's transcription request could be routed to the same Transcription worker by using sticky sessions which are managed within the L4 LB.

Note: L4 load balancers can be stateful and use sticky sessions to persist the server the client previously connected to. The sticky session can be implemented by identifying the user, usually with cookies or their IP address, and storing the user’s connected server for handling future requests.

### Handling failure of Transcription workers

- During a network partition within the Transcription workers, we want to avoid having a "lost transcription output" where we don't know if a Transcription worker is down or not. Since the worker is down or can't communicate due to a network partition, the response won't be generated.

- To fix this "lost worker" issue, a lastHeartbeat field can be used in a Workers table containing a list of Transcription workers. The lastHeartbeat field will be updated via heartbeats, let's say every 30 secs or so by the Transcription worker handling the transcription request.

- We can also use a separate Monitoring service that polls the Workers table, let's say every 1 min to check the lastHeartbeat values, and if the worker's lastHeartbeat wasn't updated for a while, the worker will be considered down.

Requests can fail within a Transcription worker for the below reasons - and we want to handle these failures:
- Visible failure:
  - The request fails visibly in some way, likely due to a bug in the Transcription worker code or container code.
- Invisible failure:
  - The request fails invisibly, likely due to the worker crashing

#### Handling visible failures

- Handling visible failures is easier, and can be wrapped up in a try / catch block so that we can log the error. The request can then be re-tried by letting the Live response server resend the transcription request.

#### Handling invisible failures or lost transcription responses

- When a worker crashes or becomes unresponsive, we need a reliable way to detect this and retry the request using the below approaches, and in 'Handling invisible failures' (taken from the SDI 'Distributed job scheduler'):
  - Heartbeats / health check endpoints
  - Job leasing

### Ensuring the system is scalable to support thousands of client messages per second

We can scale the system by looking from left to right looking for any bottleneck and addressing them:

#### Database

- Our Messages table looks as follows, and can be queried by using a specific conversationID (partition key), and getting back all the messages sorted by the userID + sentAt clustering keys. This means that the Live response servers will only need to read from / write to a single node via the conversationID.

```cql
create table messages (
  conversationID uuid,
  userID uuid,
  messageID uuid,
  transcription text,
  audio blob,
  sentAt timestamp,
  primary key (conversationID, (userID, sentAt))
with clustering order by (userID, sentAt asc))
```

- Also, we can move the older conversations and messages to a cheaper cold storage like S3.

#### Live response servers

- Via the L4 LB's sticky sessions, we ensure that users in the same conversationID are connected to the same Live response server - this will reduce the number of subscriptions and publishing which Redis PubSub needs to manage, thus the all-to-all connections between the Live response servers and the Redis PubSub servers will be reduced greatly.

- If for a single conversationID, all the users are already in the same Live response server (due to the L4 LB's sticky sessions), then this Live response server doesn't need to subscribe to a channel within Redis PubSub because the Live response server can respond to the already connected clients for the specific conversationID (reducing the connections to Redis PubSub servers).

#### Transcription workers

We can have the workers be either containers (using ECS or Kubernetes) or Lambda functions. These are the main options which can be started up quickly, without much downtime:
- Containers:
  - Contains tend to be more cost-effective if they're configured properly, and are better for long-running executions since they maintain state between executions inside volumes. However, they do require more operational overhead and don't scale as well as serverless options.
In this case, the containers will have the transcription code

- Lambda functions:
  - Lambda functions provide very minimal operational overhead. They're perfect for short-lived executions under 15 minutes, and can auto-scale instantly to match the workload. However, because Lambda functions can only run for max 15 mins, we can't use them for long conversations.

We went with using a container mainly because the transcription logic could take several minutes to handle a request in some cases, and Lambda has a max timeout of 15 mins. Containers also allow us to optimize the configuration such that we can have different types of containers catered to different types of requests (compute, memory, IO, network, etc optimized). We can also set up scaling policies within ECS to start up more containers - such as scaling the containers based on the number of websocket connections between the Live response servers and Transcription workers.

Note: we could also use spot instances instead of containers to reduce costs by 70%.

<br/>
<br/>

Additional deep dives:

### Cache to improve read latency of current conversation

- Because the recent conversations and messages data will likely be frequently accessed by the client, we can also store recent or current conversations and messages data within Redis sorted sets, where the score is the respective timestamp fields, createdAt and sentAt.

- Thus, the Live response servers could store the transcription outputs in Cassandra, and via Cassandra's CDC feature, the transcription outputs could then be stored in the Redis sorted set for the current conversation (because it's likely clients will want to read their current convos frequently).

- Note that Redis sorted sets are also used in this design to reduce some of the read latency for reads made to Cassandra. Cassandra optimizes write throughput over reads - reads are a bit more expensive in Cassandra because it needs to look at both memtables and SSTables to retrieve the data via the partition key.

### Blob store

- Cassandra provides a blob type to store the audio data, however, optionally the same audio data could instead be stored in a blob store like S3 and referenced using a s3URL from the Messages table.











